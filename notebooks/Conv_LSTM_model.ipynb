{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow Model !\n",
    "import tensorflow as tf\n",
    "from cell import ConvLSTMCell\n",
    "\n",
    "# Run when your in trouble ... !\n",
    "tf.reset_default_graph()\n",
    "\n",
    "class conv_lstm_model():\n",
    "    def __init__(self):\n",
    "        \"\"\"Parameter initialization\"\"\"\n",
    "        self.batch_size = 128\n",
    "        self.timesteps = 32\n",
    "        self.shape = [64, 64] # Image shape\n",
    "        self.kernel = [3, 3]\n",
    "        self.channels = 3\n",
    "        self.filters = [32,128,32,3] # 4 stacked conv lstm filters\n",
    "        \n",
    "        # Create a placeholder for videos.\n",
    "        self.inputs = tf.placeholder(tf.float32, [batch_size, timesteps] + shape + [channels]) # (batch_size, timestep, H, W, C)\n",
    "        self.outputs_exp = tf.placeholder(tf.float32, [batch_size, timesteps] + shape + [channels] ) # (batch_size, timestep, H, W, C)\n",
    "        \n",
    "        # model output\n",
    "        self.model_output = None\n",
    "        \n",
    "        # loss\n",
    "        self.l2_loss = None\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = None\n",
    "        \n",
    "    def create_model(self):\n",
    "        cells = []\n",
    "        for i, each_filter in enumerate(self.filters):\n",
    "            cell = ConvLSTMCell(self.shape, each_filter, self.kernel)\n",
    "            cells.append(cell)\n",
    "            \n",
    "        cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)        \n",
    "        states_series, current_state = tf.nn.dynamic_rnn(cell, self.inputs, dtype=self.inputs.dtype)\n",
    "        # current_state => Not used ... \n",
    "        self.model_output = states_series\n",
    "    \n",
    "    def loss(self):\n",
    "        frames_difference = tf.subtract(self.outputs_exp, self.model_output)\n",
    "        batch_l2_loss = tf.nn.l2_loss(frames_difference)\n",
    "        # divide by batch size ... \n",
    "        l2_loss = tf.divide(batch_l2_loss, float(batch_size))\n",
    "        self.l2_loss = l2_loss\n",
    "    \n",
    "    def optimize(self):\n",
    "        train_step = tf.train.AdamOptimizer().minimize(self.l2_loss)\n",
    "        self.optimizer = train_step\n",
    "        \n",
    "model = conv_lstm_model()\n",
    "model.create_model()\n",
    "model.loss()\n",
    "model.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMStateTuple(c=TensorShape([Dimension(64), Dimension(64), Dimension(12)]), h=TensorShape([Dimension(64), Dimension(64), Dimension(12)]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
