{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow Model !\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "from cell import ConvLSTMCell\n",
    "import sys\n",
    "module_path = os.path.join(\"/home/pratik/work/dl/deepvideos/model/../\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from datasets.batch_generator import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "timesteps = 32\n",
    "shape = [64, 64]  # Image shape\n",
    "kernel = [3, 3]\n",
    "channels = 3\n",
    "filters = [32, 128, 32, 3]  # 4 stacked conv lstm filters\n",
    "\n",
    "# Create a placeholder for videos.\n",
    "inputs = tf.placeholder(tf.float32, [batch_size, timesteps] + shape + [channels], name=\"conv_lstm_inputs\")  # (batch_size, timestep, H, W, C)\n",
    "outputs_exp = tf.placeholder(tf.float32, [batch_size, timesteps] + shape + [channels], name=\"conv_lstm_outputs_exp\")  # (batch_size, timestep, H, W, C)\n",
    "\n",
    "# model output\n",
    "model_output = None\n",
    "\n",
    "# loss\n",
    "l2_loss = None\n",
    "\n",
    "# optimizer\n",
    "optimizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv_lstm_inputs:0' shape=(4, 32, 64, 64, 3) dtype=float32>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_inp_reshape_size = [batch_size * timesteps,]+shape+[channels,]\n",
    "conv_input = tf.reshape(inputs, conv_inp_reshape_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "slim = tf.contrib.slim\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.contrib.layers.python.layers import regularizers\n",
    "trunc_normal = lambda stddev: init_ops.truncated_normal_initializer(0.0, stddev)\n",
    "l2_val = 0.00005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.contrib.slim.conv2d?\n",
    "#tf.contrib.slim.max_pool2d?\n",
    "tf.contrib.slim.conv2d_transpose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv_before_lstm/conv_1/Relu:0\", shape=(128, 64, 64, 32), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/conv_2/Relu:0\", shape=(128, 64, 64, 64), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/pool_1/MaxPool:0\", shape=(128, 32, 32, 64), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/conv_3/Relu:0\", shape=(128, 32, 32, 32), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/pool_2/MaxPool:0\", shape=(128, 16, 16, 32), dtype=float32)\n",
      "Tensor(\"conv_before_lstm/conv_4/Relu:0\", shape=(128, 16, 16, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('conv_before_lstm'):\n",
    "    net = slim.conv2d(conv_input, 32, [3,3], scope='conv_1',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    print (net)\n",
    "    net = slim.conv2d(net, 64, [3,3], scope='conv_2',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    print (net)\n",
    "    net = slim.max_pool2d(net, [2,2], scope='pool_1')\n",
    "    print (net)\n",
    "    net = slim.conv2d(net, 32, [3,3], scope='conv_3',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    print (net)\n",
    "    net = slim.max_pool2d(net, [2,2], scope='pool_2')\n",
    "    print (net)\n",
    "    net = slim.conv2d(net, 32, [3,3], scope='conv_4',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    print (net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_1:0\", shape=(4, 32, 16, 16, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "net_output_shape =  net.get_shape().as_list()\n",
    "lstm_reshape_size = [batch_size, timesteps] + net_output_shape[1:]\n",
    "lstm_reshape = tf.reshape(net, lstm_reshape_size)\n",
    "print lstm_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [128, 128]\n",
    "batch_size, time_step, H, W, C = lstm_reshape.get_shape().as_list()\n",
    "with tf.variable_scope('conv_lstm_model'):\n",
    "    cells = []\n",
    "    for i, each_filter in enumerate(filters):\n",
    "        cell = ConvLSTMCell([H,W], each_filter, kernel)\n",
    "        cells.append(cell)\n",
    "\n",
    "    cell = tf.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)        \n",
    "    states_series, current_state = tf.nn.dynamic_rnn(cell, lstm_reshape, dtype=lstm_reshape.dtype)\n",
    "    # current_state => Not used ... \n",
    "    model_output = states_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv_lstm_model_1/rnn/transpose:0' shape=(4, 32, 16, 16, 128) dtype=float32>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_2:0' shape=(128, 16, 16, 128) dtype=float32>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, time_step, H, W, C = model_output.get_shape().as_list()\n",
    "deconv_reshape = tf.reshape(model_output, [batch_size*time_step, H, W, C])\n",
    "deconv_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"deconv_after_lstm/deconv_1/Relu:0\", shape=(128, 16, 16, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('deconv_after_lstm'):\n",
    "    net = slim.conv2d_transpose(deconv_reshape, 64, [3,3], scope='deconv_1',weights_initializer=trunc_normal(0.01),weights_regularizer=regularizers.l2_regularizer(l2_val))\n",
    "    print net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Working on deconv .... "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
